{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps\n",
    "import json\n",
    "import os, sys\n",
    "from os.path import join\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_watson.tone_analyzer_v3 import ToneInput\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GKEY = 'AIzaSyANBKTnUtFUgYga3F-gzM6qwdNFaUul8Gg'\n",
    "from tweepy import Stream, OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import time, json, re\n",
    "from geopy import geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "g = geocoders.GoogleV3(api_key=GKEY)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AccessCodes\n",
    "consumerKey = \"TTbRIgdtpJUcQUSVZe19IurDc\"\n",
    "consumerSecret = \"hf54y1TpkhpxkhLQBMmJvbTMfFMMUfGbgYZw5xbswIad3ZWzer\"\n",
    "accessToken = \"372330040-UqVzc2sUKDFz8ZDUowAufuyAv5uaxmbvGnXTyhj3\"\n",
    "accessSecret = \"6vArqK40I23JURV8Uevek7PNvBqCfY0nhlmVJ2hsQ1zEm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample datasets\n",
    "import gmaps.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps.configure(api_key=GKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "Here we parse the tweets and create a pandas dataset\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a lat and long bounding box over the United States\n",
    "US_geobox = [-171.791110603, 18.91619, -66.96466, 71.3577635769]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "4\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "16\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "256\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "65536\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "4\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "16\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "256\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "65536\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "4\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "16\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "256\n",
      "AAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "65536\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "4\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "16\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "256\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "65536\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "4\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "16\n",
      "Exception  HTTP Error 429: Too Many Requests\n",
      "AAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Exception  HTTP Error 429: Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "#Scraping/ParsingTweets\n",
    "class Listener(StreamListener):\n",
    "    def __init__(self):\n",
    "        self.tweet_len_accept = 45\n",
    "        self.break_at = 1000\n",
    "        self.panda_list = []\n",
    "        self.count = 0\n",
    "        self.dfObj = pd.DataFrame()\n",
    "        self.exp_backoff = 2\n",
    "\n",
    "    def on_data(self, raw_data):\n",
    "        if self.count > self.break_at:\n",
    "            self.dfObj = pd.DataFrame(self.panda_list, columns =['date_obj', 'tweet', 'latitude', 'longitude'])\n",
    "            return False\n",
    "        try:\n",
    "            \n",
    "            jsonData = json.loads(raw_data)\n",
    "            #Converting date to datetime format:\n",
    "            date = jsonData['created_at']\n",
    "            date2 = str(date).split(' ')\n",
    "            date3 = date2[1]+' '+date2[2]+' '+date2[3]+' '+date2[5]\n",
    "            datetime_object = time.strptime(date3, '%b %d %H:%M:%S %Y')\n",
    "            dt = datetime.fromtimestamp(mktime(datetime_object))\n",
    "            #Parsing tweet and location:\n",
    "            pretweet = jsonData['text']\n",
    "            userInfo = jsonData['user']\n",
    "            location = userInfo['location']\n",
    "        \n",
    "            if jsonData['lang'] == 'en' and location!= 'Whole World' and location != 'Earth':\n",
    "                #print(dt, pretweet, location)\n",
    "                geolocator = Nominatim(user_agent=\"my-application\")\n",
    "                #geolocation = g.geocode(location, timeout=10)\n",
    "                geolocation = geolocator.geocode(location)\n",
    "                try:\n",
    "                    self.exp_backoff = 2\n",
    "                    #The 2-5 len range helps to remove inaccurate/unspecific locations\n",
    "                    if \"United States of America\" in geolocation.address[::] and 5>= len(geolocation.address.split(\",\")) > 2 :\n",
    "                        \n",
    "                        lat = geolocation.latitude\n",
    "                        lon = geolocation.longitude\n",
    "     \n",
    "                        if not jsonData['retweeted'] and 'RT @' not in pretweet:\n",
    "                            dt = str(dt)\n",
    "                            tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",pretweet).split())\n",
    "                            tweet_len = len(tweet)\n",
    "                            if tweet_len > self.tweet_len_accept:\n",
    "                                print(self.count,tweet)\n",
    "                                new_list = [dt, tweet, lat, lon]\n",
    "                                self.panda_list.append(new_list)\n",
    "                                self.count +=1\n",
    "                except Exception as e:\n",
    "                    print(\"Exception\", e)\n",
    "        except BaseException as e:\n",
    "            print(\"Exception \", e)\n",
    "            time.sleep(self.exp_backoff)\n",
    "            self.exp_backoff **=2\n",
    "            print(self.exp_backoff)\n",
    "            if self.exp_backoff >= 900:\n",
    "                self.exp_backoff = 2\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Status code\", status_code)\n",
    "\n",
    "#Access\n",
    "auth = OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessSecret)\n",
    "\n",
    "#InitiateStreaming\n",
    "listener = Listener()\n",
    "\n",
    "# twitterStream = Stream(auth, listener, verify = False)\n",
    "# twitterStream.filter(locations=US_geobox, is_async=True, stall_warnings=True)\n",
    "\n",
    "def start_stream():\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"AAAAAAAAAAAAAAAAAAAAAAAA\")\n",
    "            twitterStream = Stream(auth, listener)\n",
    "            twitterStream.filter(locations=US_geobox)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "start_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = listener.dfObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "RUN the tweets through the tone analyzer\n",
    "\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('WWfYmUhjlV60EA-ZwfhXG7n1eopAyoc8B8veLjpMn4J0')\n",
    "service = ToneAnalyzerV3(\n",
    "    version='2017-09-21',\n",
    "    authenticator=authenticator)\n",
    "#service.set_service_url('https://gateway.watsonplatform.net/tone-analyzer/api')\n",
    "service.set_service_url('https://api.us-south.tone-analyzer.watson.cloud.ibm.com/instances/71cb1ee3-d68b-4688-a041-04e72b826f2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_list = []\n",
    "emotion_list = []\n",
    "score_list = []\n",
    "for index, row in df.iterrows():\n",
    "    text = str(row['tweet'])\n",
    "    #print(text)\n",
    "    data = service.tone(\n",
    "    {'text': text},\n",
    "    content_type='application/json'\n",
    "    ).get_result()\n",
    "    ## parse dictionary\n",
    "    for key, value in (data[\"document_tone\"]).items():\n",
    "        ## is value an empty list\n",
    "        empty = len(value)\n",
    "        if empty == 0:\n",
    "            score_list.append(0)\n",
    "            emotion_list.append(\"null\")\n",
    "        else:\n",
    "            ## value is a dictionary list \n",
    "            mag = 0\n",
    "            #max_tone = \"\"\n",
    "            next_item = False\n",
    "            for item in value:\n",
    "                for needle, record in item.items():\n",
    "                    if needle == 'tone_id' and (next_item == True):\n",
    "                        next_item = False\n",
    "                        max_tone = record\n",
    "                    if needle == 'score':\n",
    "                        if record > mag:\n",
    "                            next_item = True\n",
    "                            mag = record\n",
    "                        else:\n",
    "                            next_item = False\n",
    "            emotion_list.append(max_tone)\n",
    "            score_list.append(mag)\n",
    "        \n",
    "## Add new columns to the dataframe\n",
    "df[\"magnitude\"] = score_list\n",
    "df[\"emotion\"] = emotion_list\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################\n",
    "\n",
    "Here we are going to add the datasets created and create a heatmap of the United States based on the Emotion chosen. \n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['emotion'] == 'joy']\n",
    "\n",
    "#earthquake_df = gmaps.datasets.load_dataset_as_df('earthquakes')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df[['latitude', 'longitude']]\n",
    "weights = df['magnitude']\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations, weights=weights))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
