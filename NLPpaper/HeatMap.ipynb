{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################<br>\n",
    "Isaac G Callison</br>\n",
    "\n",
    "Tone Analyzer<br>\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps\n",
    "import json\n",
    "import os, sys\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_watson.tone_analyzer_v3 import ToneInput\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream, OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import time, json, re\n",
    "from geopy import geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "# google maps key used for map and geocode.\n",
    "GKEY = 'AIzaSyANBKTnUtFUgYga3F-gzM6qwdNFaUul8Gg'\n",
    "g = geocoders.GoogleV3(api_key=GKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AccessCodes and API keys\n",
    "consumerKey = \"TTbRIgdtpJUcQUSVZe19IurDc\"\n",
    "consumerSecret = \"hf54y1TpkhpxkhLQBMmJvbTMfFMMUfGbgYZw5xbswIad3ZWzer\"\n",
    "accessToken = \"372330040-UqVzc2sUKDFz8ZDUowAufuyAv5uaxmbvGnXTyhj3\"\n",
    "accessSecret = \"6vArqK40I23JURV8Uevek7PNvBqCfY0nhlmVJ2hsQ1zEm\"\n",
    "gmaps.configure(api_key=GKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "The following are bounding boxes of latitudes and longitudes that we can focus in on to \n",
    "get tweets from. \n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a lat and long bounding box over the United States, Hawaii, NYC, and Nashville\n",
    "            #top left       bottom lft  top right  bottom right\n",
    "US_geobox = [-171.791110603, 18.91619, -66.96466, 71.3577635769]\n",
    "Hawaii = [-160.161542, 18.776344, -154.641396, 22.878623] \n",
    "NY = [-74.2242920399,40.4774831063,-72.7576172352,40.9625046653]\n",
    "Nashville = [-86.8959915638,36.0816806419,-86.6343796253,36.2446612608]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "This class is used to stream tweets \n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to one of the above to change location that tweets are pulled from. \n",
    "bounding_box = NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Starting Stream (this resets every 40 tweets or so)\n",
      "0 Am I the only one refreshing his page every 10 mins\n",
      "1\n",
      "Starting Stream (this resets every 40 tweets or so)\n"
     ]
    }
   ],
   "source": [
    "#Scraping/ParsingTweets\n",
    "class Listener(StreamListener):\n",
    "    def __init__(self):\n",
    "        self.tweet_len_accept = 45 # min length tweet we will accept, filter out incomplete thoughts\n",
    "        self.break_at = 15 #The number of \"good\" tweets that we will pull before moving on, rate limits at 293 or so.\n",
    "        self.panda_list = []\n",
    "        self.count = 0\n",
    "        self.dfObj = pd.DataFrame()\n",
    "        self.exp_backoff = 2 # If rate limited, this is the factor used to reset the time to try again.\n",
    "\n",
    "    def on_data(self, raw_data):\n",
    "        if self.count >= self.break_at: # If we hit the break point, we create the panda dataframe and return false\n",
    "            self.dfObj = pd.DataFrame(self.panda_list, columns =['date_obj', 'tweet', 'latitude', 'longitude'])\n",
    "            return False\n",
    "        try:         \n",
    "            jsonData = json.loads(raw_data)\n",
    "            #Converting date to datetime format:\n",
    "            date = jsonData['created_at']\n",
    "            date2 = str(date).split(' ')\n",
    "            date3 = date2[1]+' '+date2[2]+' '+date2[3]+' '+date2[5]\n",
    "            datetime_object = time.strptime(date3, '%b %d %H:%M:%S %Y')\n",
    "            dt = datetime.fromtimestamp(mktime(datetime_object))\n",
    "            #Parsing tweet and location:\n",
    "            pretweet = jsonData['text']\n",
    "            userInfo = jsonData['user']\n",
    "            location = userInfo['location']\n",
    "            #print(pretweet)\n",
    "            # pull english tweets for parsing. Should already be filtered by bounding lats and long.\n",
    "            if jsonData['lang'] == 'en':\n",
    "                geolocator = Nominatim(user_agent=\"my-application\")\n",
    "                geolocation = geolocator.geocode(location)\n",
    "                try:\n",
    "                    self.exp_backoff = 2\n",
    "                    #The 2-5 len range helps to remove inaccurate/unspecific locations\n",
    "                    if (5>= len(geolocation.address.split(\",\")) > 2) and (\"None\" not in geolocation.address[::]):\n",
    "                        #print(geolocation.address)\n",
    "                        \n",
    "                        lat = geolocation.latitude; lon = geolocation.longitude\n",
    "                        #if not jsonData['retweeted'] and 'RT @' not in pretweet:\n",
    "                        dt = str(dt)\n",
    "                        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",pretweet).split())\n",
    "                        tweet_len = len(tweet)\n",
    "                        if tweet_len > self.tweet_len_accept:\n",
    "                            print(self.count,tweet)\n",
    "                            new_list = [dt, tweet, lat, lon]\n",
    "                            self.panda_list.append(new_list)\n",
    "                            self.count +=1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    #print(\"address nonetype: \", e)\n",
    "                    \n",
    "        except BaseException as e:\n",
    "            print(\"BaseException \", e)\n",
    "            time.sleep(self.exp_backoff)\n",
    "            self.exp_backoff **=2\n",
    "            print(self.exp_backoff)\n",
    "            if self.exp_backoff >= 900:\n",
    "                self.exp_backoff = 2\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Status code\", status_code)\n",
    "\n",
    "#Access\n",
    "auth = OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessSecret)\n",
    "\n",
    "#InitiateStreaming\n",
    "listener = Listener()\n",
    "## Start the stream, stop if certain conditions met. Restarting the stream was necessary at times because the \n",
    "## amount of data coming in was too much for the functions parsing it. \n",
    "def start_stream():\n",
    "    streaming = True\n",
    "    while streaming == True:\n",
    "        print(listener.count)\n",
    "        try:\n",
    "            print(\"Starting Stream (this resets every 40 tweets or so)\")\n",
    "            if listener.count >=listener.break_at:\n",
    "                streaming = False\n",
    "            twitterStream = Stream(auth, listener)\n",
    "            twitterStream.filter(locations=bounding_box)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "start_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = listener.dfObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "RUN the tweets through the tone analyzer\n",
    "\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up the Watson Tone Analyzer API\n",
    "authenticator = IAMAuthenticator('WWfYmUhjlV60EA-ZwfhXG7n1eopAyoc8B8veLjpMn4J0')\n",
    "service = ToneAnalyzerV3(\n",
    "    version='2017-09-21',\n",
    "    authenticator=authenticator)\n",
    "service.set_service_url('https://api.us-south.tone-analyzer.watson.cloud.ibm.com/instances/71cb1ee3-d68b-4688-a041-04e72b826f2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_obj</th>\n",
       "      <th>tweet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-10 02:53:26</td>\n",
       "      <td>THANK YOU EVERYONE for all the quarantine birt...</td>\n",
       "      <td>40.789624</td>\n",
       "      <td>-73.959894</td>\n",
       "      <td>0.957250</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-10 02:53:28</td>\n",
       "      <td>wait i thought this was just a joke MFS REALLY...</td>\n",
       "      <td>40.749824</td>\n",
       "      <td>-73.797634</td>\n",
       "      <td>0.867767</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-10 02:53:39</td>\n",
       "      <td>I m planning on keeping my bedroom but using t...</td>\n",
       "      <td>40.846651</td>\n",
       "      <td>-73.878594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-10 02:53:44</td>\n",
       "      <td>Get me George Soros USA was contributing abt 5...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-10 02:53:46</td>\n",
       "      <td>All these IG STORY shows are getting corny now</td>\n",
       "      <td>40.749824</td>\n",
       "      <td>-73.797634</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-04-10 02:53:50</td>\n",
       "      <td>Annalise is trying to save Frank and Bonnie an...</td>\n",
       "      <td>43.151860</td>\n",
       "      <td>-76.061193</td>\n",
       "      <td>0.798791</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-04-10 02:54:02</td>\n",
       "      <td>I m obsessed I however am a Reese Kerry fan It...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.731735</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-04-10 02:54:07</td>\n",
       "      <td>By the way when can I get it and could you ple...</td>\n",
       "      <td>40.779545</td>\n",
       "      <td>-74.023751</td>\n",
       "      <td>0.749480</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-04-10 02:54:13</td>\n",
       "      <td>Just wait until he s been unleashed Because on...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.856622</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-04-10 02:54:22</td>\n",
       "      <td>Omg noooo The ones I heard are already removed...</td>\n",
       "      <td>40.789624</td>\n",
       "      <td>-73.959894</td>\n",
       "      <td>0.603065</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-10 02:54:30</td>\n",
       "      <td>orange Yea you just pay shipping I just printe...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.946222</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-04-10 02:54:31</td>\n",
       "      <td>Yeah I was one of the members of my branch I j...</td>\n",
       "      <td>42.651167</td>\n",
       "      <td>-73.754968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-04-10 02:54:35</td>\n",
       "      <td>Thank God we have an America first President A...</td>\n",
       "      <td>41.435179</td>\n",
       "      <td>-73.117277</td>\n",
       "      <td>0.768551</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-04-10 02:54:37</td>\n",
       "      <td>Someone I Love Who Works In A Hospital Broke D...</td>\n",
       "      <td>40.871537</td>\n",
       "      <td>-73.048404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-04-10 02:54:52</td>\n",
       "      <td>Construction on SouthernStateParkway EB from E...</td>\n",
       "      <td>45.148951</td>\n",
       "      <td>-66.958631</td>\n",
       "      <td>0.762356</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_obj                                              tweet  \\\n",
       "0   2020-04-10 02:53:26  THANK YOU EVERYONE for all the quarantine birt...   \n",
       "1   2020-04-10 02:53:28  wait i thought this was just a joke MFS REALLY...   \n",
       "2   2020-04-10 02:53:39  I m planning on keeping my bedroom but using t...   \n",
       "3   2020-04-10 02:53:44  Get me George Soros USA was contributing abt 5...   \n",
       "4   2020-04-10 02:53:46     All these IG STORY shows are getting corny now   \n",
       "5   2020-04-10 02:53:50  Annalise is trying to save Frank and Bonnie an...   \n",
       "6   2020-04-10 02:54:02  I m obsessed I however am a Reese Kerry fan It...   \n",
       "7   2020-04-10 02:54:07  By the way when can I get it and could you ple...   \n",
       "8   2020-04-10 02:54:13  Just wait until he s been unleashed Because on...   \n",
       "9   2020-04-10 02:54:22  Omg noooo The ones I heard are already removed...   \n",
       "10  2020-04-10 02:54:30  orange Yea you just pay shipping I just printe...   \n",
       "11  2020-04-10 02:54:31  Yeah I was one of the members of my branch I j...   \n",
       "12  2020-04-10 02:54:35  Thank God we have an America first President A...   \n",
       "13  2020-04-10 02:54:37  Someone I Love Who Works In A Hospital Broke D...   \n",
       "14  2020-04-10 02:54:52  Construction on SouthernStateParkway EB from E...   \n",
       "\n",
       "     latitude  longitude  magnitude     emotion  \n",
       "0   40.789624 -73.959894   0.957250         joy  \n",
       "1   40.749824 -73.797634   0.867767   tentative  \n",
       "2   40.846651 -73.878594   0.000000        null  \n",
       "3   40.650104 -73.949582   0.559788         joy  \n",
       "4   40.749824 -73.797634   0.874372   confident  \n",
       "5   43.151860 -76.061193   0.798791   tentative  \n",
       "6   40.650104 -73.949582   0.731735  analytical  \n",
       "7   40.779545 -74.023751   0.749480  analytical  \n",
       "8   40.650104 -73.949582   0.856622   tentative  \n",
       "9   40.789624 -73.959894   0.603065     sadness  \n",
       "10  40.650104 -73.949582   0.946222   tentative  \n",
       "11  42.651167 -73.754968   0.000000        null  \n",
       "12  41.435179 -73.117277   0.768551         joy  \n",
       "13  40.871537 -73.048404   0.000000        null  \n",
       "14  45.148951 -66.958631   0.762356  analytical  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data is returned in a nested JSON format which was fairly difficult to parse. Several emotional states\n",
    "# might have been returned from a single tweet, or none at all. The predominant emotional state, the one with the\n",
    "# largest magnitude was choosen. If there was no emotional state assigned, a value of Null was inserted. \n",
    "\n",
    "mag_list = []\n",
    "emotion_list = []\n",
    "score_list = []\n",
    "for index, row in df.iterrows():\n",
    "    text = str(row['tweet'])\n",
    "    #print(text)\n",
    "    data = service.tone(\n",
    "    {'text': text},\n",
    "    content_type='application/json'\n",
    "    ).get_result()\n",
    "    ## parse dictionary\n",
    "    for key, value in (data[\"document_tone\"]).items():\n",
    "        ## is value an empty list\n",
    "        empty = len(value)\n",
    "        if empty == 0:\n",
    "            score_list.append(0)\n",
    "            emotion_list.append(\"null\")\n",
    "        else:\n",
    "            ## value is a dictionary list \n",
    "            mag = 0\n",
    "            #max_tone = \"\"\n",
    "            next_item = False\n",
    "            for item in value:\n",
    "                for needle, record in item.items():\n",
    "                    if needle == 'tone_id' and (next_item == True):\n",
    "                        next_item = False\n",
    "                        max_tone = record\n",
    "                    if needle == 'score':\n",
    "                        if record > mag:\n",
    "                            next_item = True\n",
    "                            mag = record\n",
    "                        else:\n",
    "                            next_item = False\n",
    "            emotion_list.append(max_tone)\n",
    "            score_list.append(mag)\n",
    "        \n",
    "## Add new columns to the dataframe\n",
    "df[\"magnitude\"] = score_list\n",
    "df[\"emotion\"] = emotion_list\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################\n",
    "\n",
    "Here we are going to add the datasets created and create a heatmap of the United States based on the Emotion chosen. \n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe lists several different emotions. Setting The Dataframe variable\n",
    "# to one in particular will select all rows containing that emotion from the list. \n",
    "\n",
    "df_fear = df.loc[df['emotion'] == 'fear']\n",
    "df_joy = df.loc[df['emotion'] == 'joy']\n",
    "df_sadness = df.loc[df['emotion'] == 'sadness']\n",
    "df_analytical = df.loc[df['emotion'] == 'analytical']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = df_joy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_obj</th>\n",
       "      <th>tweet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-10 02:53:26</td>\n",
       "      <td>THANK YOU EVERYONE for all the quarantine birt...</td>\n",
       "      <td>40.789624</td>\n",
       "      <td>-73.959894</td>\n",
       "      <td>0.957250</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-10 02:53:44</td>\n",
       "      <td>Get me George Soros USA was contributing abt 5...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-04-10 02:54:35</td>\n",
       "      <td>Thank God we have an America first President A...</td>\n",
       "      <td>41.435179</td>\n",
       "      <td>-73.117277</td>\n",
       "      <td>0.768551</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_obj                                              tweet  \\\n",
       "0   2020-04-10 02:53:26  THANK YOU EVERYONE for all the quarantine birt...   \n",
       "3   2020-04-10 02:53:44  Get me George Soros USA was contributing abt 5...   \n",
       "12  2020-04-10 02:54:35  Thank God we have an America first President A...   \n",
       "\n",
       "     latitude  longitude  magnitude emotion  \n",
       "0   40.789624 -73.959894   0.957250     joy  \n",
       "3   40.650104 -73.949582   0.559788     joy  \n",
       "12  41.435179 -73.117277   0.768551     joy  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING The map may only display in a jupyter Notebook and not in Jupyter Lab. \n",
    "locations = DataFrame[['latitude', 'longitude']]\n",
    "weights = DataFrame['magnitude']\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations, weights=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18f15b824ce469b9ceb52abd65525df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
