{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################<br>\n",
    "Isaac G Callison</br>\n",
    "\n",
    "Tone Analyzer<br>\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps\n",
    "import json\n",
    "import os, sys\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_watson.tone_analyzer_v3 import ToneInput\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream, OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import time, json, re\n",
    "from geopy import geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "# google maps key used for map and geocode.\n",
    "GKEY = 'AIzaSyANBKTnUtFUgYga3F-gzM6qwdNFaUul8Gg'\n",
    "g = geocoders.GoogleV3(api_key=GKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AccessCodes and API keys\n",
    "consumerKey = \"TTbRIgdtpJUcQUSVZe19IurDc\"\n",
    "consumerSecret = \"hf54y1TpkhpxkhLQBMmJvbTMfFMMUfGbgYZw5xbswIad3ZWzer\"\n",
    "accessToken = \"372330040-UqVzc2sUKDFz8ZDUowAufuyAv5uaxmbvGnXTyhj3\"\n",
    "accessSecret = \"6vArqK40I23JURV8Uevek7PNvBqCfY0nhlmVJ2hsQ1zEm\"\n",
    "gmaps.configure(api_key=GKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "The following are bounding boxes of latitudes and longitudes that we can focus in on to \n",
    "get tweets from. \n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a lat and long bounding box over the United States, Hawaii, NYC, and Nashville\n",
    "            #top left       bottom lft  top right  bottom right\n",
    "US_geobox = [-171.791110603, 18.91619, -66.96466, 71.3577635769]\n",
    "Hawaii = [-160.161542, 18.776344, -154.641396, 22.878623] \n",
    "NY = [-74.2242920399,40.4774831063,-72.7576172352,40.9625046653]\n",
    "Nashville = [-86.8959915638,36.0816806419,-86.6343796253,36.2446612608]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "This class is used to stream tweets \n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to one of the above to change location that tweets are pulled from. \n",
    "bounding_box = NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Starting Stream (this resets every 40 tweets or so)\n",
      "0 THANK YOU EVERYONE for all the quarantine birthday love I truly appreciate all of you and I had the best possible\n",
      "1 wait i thought this was just a joke MFS REALLY BE EATING DOGS\n",
      "2 I m planning on keeping my bedroom but using the spare as an office art stuff exercise space\n",
      "3 Get me George Soros USA was contributing abt 58M to WHO Let s raise Trump a cool 58M All we need is 120 benevo\n",
      "4 All these IG STORY shows are getting corny now\n",
      "5 Annalise is trying to save Frank and Bonnie and still they want to stay around HTGAWM\n",
      "6 I m obsessed I however am a Reese Kerry fan It s nothing really new from THEM but the story and the\n",
      "7 By the way when can I get it and could you please drop the dlc earlier\n",
      "8 Just wait until he s been unleashed Because only he can speak about topics like impeachment and w\n",
      "9 Omg noooo The ones I heard are already removed But I heard a fake one There was a new Babylon clip and Free Woman clip\n",
      "10 orange Yea you just pay shipping I just printed out 150 prints\n",
      "11 Yeah I was one of the members of my branch I just loved being the topic of THAT e mail\n",
      "12 Thank God we have an America first President A strong America means a free world\n",
      "13 Someone I Love Who Works In A Hospital Broke Down Today I ve Always Defended This Person Since We Were Kids Wh\n",
      "14 Construction on SouthernStateParkway EB from Exit 14 Fletcher Avenue EB to Exit 15 North Corona Avenue\n",
      "15\n",
      "Starting Stream (this resets every 40 tweets or so)\n"
     ]
    }
   ],
   "source": [
    "#Scraping/ParsingTweets\n",
    "class Listener(StreamListener):\n",
    "    def __init__(self):\n",
    "        self.tweet_len_accept = 45 # min length tweet we will accept, filter out incomplete thoughts\n",
    "        self.break_at = 15 #The number of \"good\" tweets that we will pull before moving on, rate limits at 293 or so.\n",
    "        self.panda_list = []\n",
    "        self.count = 0\n",
    "        self.dfObj = pd.DataFrame()\n",
    "        self.exp_backoff = 2 # If rate limited, this is the factor used to reset the time to try again.\n",
    "\n",
    "    def on_data(self, raw_data):\n",
    "        if self.count >= self.break_at: # If we hit the break point, we create the panda dataframe and return false\n",
    "            self.dfObj = pd.DataFrame(self.panda_list, columns =['date_obj', 'tweet', 'latitude', 'longitude'])\n",
    "            return False\n",
    "        try:         \n",
    "            jsonData = json.loads(raw_data)\n",
    "            #Converting date to datetime format:\n",
    "            date = jsonData['created_at']\n",
    "            date2 = str(date).split(' ')\n",
    "            date3 = date2[1]+' '+date2[2]+' '+date2[3]+' '+date2[5]\n",
    "            datetime_object = time.strptime(date3, '%b %d %H:%M:%S %Y')\n",
    "            dt = datetime.fromtimestamp(mktime(datetime_object))\n",
    "            #Parsing tweet and location:\n",
    "            pretweet = jsonData['text']\n",
    "            userInfo = jsonData['user']\n",
    "            location = userInfo['location']\n",
    "            # pull english tweets for parsing. Should already be filtered by bounding lats and long.\n",
    "            if jsonData['lang'] == 'en':\n",
    "                geolocator = Nominatim(user_agent=\"my-application\")\n",
    "                geolocation = geolocator.geocode(location)\n",
    "                try:\n",
    "                    self.exp_backoff = 2\n",
    "                    #The 2-5 len range helps to remove inaccurate/unspecific locations\n",
    "                    if (5>= len(geolocation.address.split(\",\")) > 2) and (\"None\" not in geolocation.address[::]):\n",
    "                        #print(geolocation.address)\n",
    "                        \n",
    "                        lat = geolocation.latitude; lon = geolocation.longitude\n",
    "                        if not jsonData['retweeted'] and 'RT @' not in pretweet:\n",
    "                            dt = str(dt)\n",
    "                            tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",pretweet).split())\n",
    "                            tweet_len = len(tweet)\n",
    "                            if tweet_len > self.tweet_len_accept:\n",
    "                                print(self.count,tweet)\n",
    "                                new_list = [dt, tweet, lat, lon]\n",
    "                                self.panda_list.append(new_list)\n",
    "                                self.count +=1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    #print(\"address nonetype: \", e)\n",
    "                    \n",
    "        except BaseException as e:\n",
    "            print(\"BaseException \", e)\n",
    "            time.sleep(self.exp_backoff)\n",
    "            self.exp_backoff **=2\n",
    "            print(self.exp_backoff)\n",
    "            if self.exp_backoff >= 900:\n",
    "                self.exp_backoff = 2\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Status code\", status_code)\n",
    "\n",
    "#Access\n",
    "auth = OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessSecret)\n",
    "\n",
    "#InitiateStreaming\n",
    "listener = Listener()\n",
    "## Start the stream, stop if certain conditions met. Restarting the stream was necessary at times because the \n",
    "## amount of data coming in was too much for the functions parsing it. \n",
    "def start_stream():\n",
    "    streaming = True\n",
    "    while streaming == True:\n",
    "        print(listener.count)\n",
    "        try:\n",
    "            print(\"Starting Stream (this resets every 40 tweets or so)\")\n",
    "            if listener.count >=listener.break_at:\n",
    "                streaming = False\n",
    "            twitterStream = Stream(auth, listener)\n",
    "            twitterStream.filter(locations=bounding_box)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "start_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = listener.dfObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "RUN the tweets through the tone analyzer\n",
    "\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up the Watson Tone Analyzer API\n",
    "authenticator = IAMAuthenticator('WWfYmUhjlV60EA-ZwfhXG7n1eopAyoc8B8veLjpMn4J0')\n",
    "service = ToneAnalyzerV3(\n",
    "    version='2017-09-21',\n",
    "    authenticator=authenticator)\n",
    "service.set_service_url('https://api.us-south.tone-analyzer.watson.cloud.ibm.com/instances/71cb1ee3-d68b-4688-a041-04e72b826f2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_obj</th>\n",
       "      <th>tweet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-10 02:53:26</td>\n",
       "      <td>THANK YOU EVERYONE for all the quarantine birt...</td>\n",
       "      <td>40.789624</td>\n",
       "      <td>-73.959894</td>\n",
       "      <td>0.957250</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-10 02:53:28</td>\n",
       "      <td>wait i thought this was just a joke MFS REALLY...</td>\n",
       "      <td>40.749824</td>\n",
       "      <td>-73.797634</td>\n",
       "      <td>0.867767</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-10 02:53:39</td>\n",
       "      <td>I m planning on keeping my bedroom but using t...</td>\n",
       "      <td>40.846651</td>\n",
       "      <td>-73.878594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-10 02:53:44</td>\n",
       "      <td>Get me George Soros USA was contributing abt 5...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-10 02:53:46</td>\n",
       "      <td>All these IG STORY shows are getting corny now</td>\n",
       "      <td>40.749824</td>\n",
       "      <td>-73.797634</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-04-10 02:53:50</td>\n",
       "      <td>Annalise is trying to save Frank and Bonnie an...</td>\n",
       "      <td>43.151860</td>\n",
       "      <td>-76.061193</td>\n",
       "      <td>0.798791</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-04-10 02:54:02</td>\n",
       "      <td>I m obsessed I however am a Reese Kerry fan It...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.731735</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-04-10 02:54:07</td>\n",
       "      <td>By the way when can I get it and could you ple...</td>\n",
       "      <td>40.779545</td>\n",
       "      <td>-74.023751</td>\n",
       "      <td>0.749480</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-04-10 02:54:13</td>\n",
       "      <td>Just wait until he s been unleashed Because on...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.856622</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-04-10 02:54:22</td>\n",
       "      <td>Omg noooo The ones I heard are already removed...</td>\n",
       "      <td>40.789624</td>\n",
       "      <td>-73.959894</td>\n",
       "      <td>0.603065</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-10 02:54:30</td>\n",
       "      <td>orange Yea you just pay shipping I just printe...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.946222</td>\n",
       "      <td>tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-04-10 02:54:31</td>\n",
       "      <td>Yeah I was one of the members of my branch I j...</td>\n",
       "      <td>42.651167</td>\n",
       "      <td>-73.754968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-04-10 02:54:35</td>\n",
       "      <td>Thank God we have an America first President A...</td>\n",
       "      <td>41.435179</td>\n",
       "      <td>-73.117277</td>\n",
       "      <td>0.768551</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-04-10 02:54:37</td>\n",
       "      <td>Someone I Love Who Works In A Hospital Broke D...</td>\n",
       "      <td>40.871537</td>\n",
       "      <td>-73.048404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-04-10 02:54:52</td>\n",
       "      <td>Construction on SouthernStateParkway EB from E...</td>\n",
       "      <td>45.148951</td>\n",
       "      <td>-66.958631</td>\n",
       "      <td>0.762356</td>\n",
       "      <td>analytical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_obj                                              tweet  \\\n",
       "0   2020-04-10 02:53:26  THANK YOU EVERYONE for all the quarantine birt...   \n",
       "1   2020-04-10 02:53:28  wait i thought this was just a joke MFS REALLY...   \n",
       "2   2020-04-10 02:53:39  I m planning on keeping my bedroom but using t...   \n",
       "3   2020-04-10 02:53:44  Get me George Soros USA was contributing abt 5...   \n",
       "4   2020-04-10 02:53:46     All these IG STORY shows are getting corny now   \n",
       "5   2020-04-10 02:53:50  Annalise is trying to save Frank and Bonnie an...   \n",
       "6   2020-04-10 02:54:02  I m obsessed I however am a Reese Kerry fan It...   \n",
       "7   2020-04-10 02:54:07  By the way when can I get it and could you ple...   \n",
       "8   2020-04-10 02:54:13  Just wait until he s been unleashed Because on...   \n",
       "9   2020-04-10 02:54:22  Omg noooo The ones I heard are already removed...   \n",
       "10  2020-04-10 02:54:30  orange Yea you just pay shipping I just printe...   \n",
       "11  2020-04-10 02:54:31  Yeah I was one of the members of my branch I j...   \n",
       "12  2020-04-10 02:54:35  Thank God we have an America first President A...   \n",
       "13  2020-04-10 02:54:37  Someone I Love Who Works In A Hospital Broke D...   \n",
       "14  2020-04-10 02:54:52  Construction on SouthernStateParkway EB from E...   \n",
       "\n",
       "     latitude  longitude  magnitude     emotion  \n",
       "0   40.789624 -73.959894   0.957250         joy  \n",
       "1   40.749824 -73.797634   0.867767   tentative  \n",
       "2   40.846651 -73.878594   0.000000        null  \n",
       "3   40.650104 -73.949582   0.559788         joy  \n",
       "4   40.749824 -73.797634   0.874372   confident  \n",
       "5   43.151860 -76.061193   0.798791   tentative  \n",
       "6   40.650104 -73.949582   0.731735  analytical  \n",
       "7   40.779545 -74.023751   0.749480  analytical  \n",
       "8   40.650104 -73.949582   0.856622   tentative  \n",
       "9   40.789624 -73.959894   0.603065     sadness  \n",
       "10  40.650104 -73.949582   0.946222   tentative  \n",
       "11  42.651167 -73.754968   0.000000        null  \n",
       "12  41.435179 -73.117277   0.768551         joy  \n",
       "13  40.871537 -73.048404   0.000000        null  \n",
       "14  45.148951 -66.958631   0.762356  analytical  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data is returned in a nested JSON format which was fairly difficult to parse. Several emotional states\n",
    "# might have been returned from a single tweet, or none at all. The predominant emotional state, the one with the\n",
    "# largest magnitude was choosen. If there was no emotional state assigned, a value of Null was inserted. \n",
    "\n",
    "mag_list = []\n",
    "emotion_list = []\n",
    "score_list = []\n",
    "for index, row in df.iterrows():\n",
    "    text = str(row['tweet'])\n",
    "    #print(text)\n",
    "    data = service.tone(\n",
    "    {'text': text},\n",
    "    content_type='application/json'\n",
    "    ).get_result()\n",
    "    ## parse dictionary\n",
    "    for key, value in (data[\"document_tone\"]).items():\n",
    "        ## is value an empty list\n",
    "        empty = len(value)\n",
    "        if empty == 0:\n",
    "            score_list.append(0)\n",
    "            emotion_list.append(\"null\")\n",
    "        else:\n",
    "            ## value is a dictionary list \n",
    "            mag = 0\n",
    "            #max_tone = \"\"\n",
    "            next_item = False\n",
    "            for item in value:\n",
    "                for needle, record in item.items():\n",
    "                    if needle == 'tone_id' and (next_item == True):\n",
    "                        next_item = False\n",
    "                        max_tone = record\n",
    "                    if needle == 'score':\n",
    "                        if record > mag:\n",
    "                            next_item = True\n",
    "                            mag = record\n",
    "                        else:\n",
    "                            next_item = False\n",
    "            emotion_list.append(max_tone)\n",
    "            score_list.append(mag)\n",
    "        \n",
    "## Add new columns to the dataframe\n",
    "df[\"magnitude\"] = score_list\n",
    "df[\"emotion\"] = emotion_list\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################################################\n",
    "\n",
    "Here we are going to add the datasets created and create a heatmap of the United States based on the Emotion chosen. \n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe lists several different emotions. Setting The Dataframe variable\n",
    "# to one in particular will select all rows containing that emotion from the list. \n",
    "\n",
    "df_fear = df.loc[df['emotion'] == 'fear']\n",
    "df_joy = df.loc[df['emotion'] == 'joy']\n",
    "df_sadness = df.loc[df['emotion'] == 'sadness']\n",
    "df_analytical = df.loc[df['emotion'] == 'analytical']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = df_joy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_obj</th>\n",
       "      <th>tweet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-10 02:53:26</td>\n",
       "      <td>THANK YOU EVERYONE for all the quarantine birt...</td>\n",
       "      <td>40.789624</td>\n",
       "      <td>-73.959894</td>\n",
       "      <td>0.957250</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-10 02:53:44</td>\n",
       "      <td>Get me George Soros USA was contributing abt 5...</td>\n",
       "      <td>40.650104</td>\n",
       "      <td>-73.949582</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-04-10 02:54:35</td>\n",
       "      <td>Thank God we have an America first President A...</td>\n",
       "      <td>41.435179</td>\n",
       "      <td>-73.117277</td>\n",
       "      <td>0.768551</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_obj                                              tweet  \\\n",
       "0   2020-04-10 02:53:26  THANK YOU EVERYONE for all the quarantine birt...   \n",
       "3   2020-04-10 02:53:44  Get me George Soros USA was contributing abt 5...   \n",
       "12  2020-04-10 02:54:35  Thank God we have an America first President A...   \n",
       "\n",
       "     latitude  longitude  magnitude emotion  \n",
       "0   40.789624 -73.959894   0.957250     joy  \n",
       "3   40.650104 -73.949582   0.559788     joy  \n",
       "12  41.435179 -73.117277   0.768551     joy  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING The map may only display in a jupyter Notebook and not in Jupyter Lab. \n",
    "locations = DataFrame[['latitude', 'longitude']]\n",
    "weights = DataFrame['magnitude']\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(gmaps.heatmap_layer(locations, weights=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18f15b824ce469b9ceb52abd65525df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
