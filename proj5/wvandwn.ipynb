{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the pruned word2vec sample in NLTK\n",
    "from nltk.data import find\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time()\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False) # load in word2vec format\n",
    "#print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's vocabulary\n",
    "vocab = set(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43981"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: words may have to be converted between lower and title case (and possibly upper case?) to see if they exist in the vocabulary\n",
    "len(model['avocado']) # dimensions of vector representing word 'avocado' (and all other words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wagons', 0.6923391819000244),\n",
       " ('buckboard', 0.5725744366645813),\n",
       " ('tractor', 0.5646649599075317),\n",
       " ('truck', 0.5361799597740173),\n",
       " ('boxcar', 0.5161231756210327),\n",
       " ('Wagon', 0.5161173939704895),\n",
       " ('stagecoach', 0.5105308890342712),\n",
       " ('van', 0.5091939568519592),\n",
       " ('boxcars', 0.508715808391571),\n",
       " ('mule', 0.49818965792655945)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('wagon', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wagons', 0.8461687564849854),\n",
       " ('buckboard', 0.7862864136695862),\n",
       " ('tractor', 0.7823317050933838),\n",
       " ('truck', 0.7680892944335938),\n",
       " ('boxcar', 0.758060872554779),\n",
       " ('Wagon', 0.7580579519271851),\n",
       " ('stagecoach', 0.7552647590637207),\n",
       " ('van', 0.7545962333679199),\n",
       " ('boxcars', 0.7543572187423706),\n",
       " ('mule', 0.7490941286087036),\n",
       " ('oxcart', 0.7466381192207336),\n",
       " ('chariot', 0.7398384809494019),\n",
       " ('buggy', 0.7397239208221436),\n",
       " ('locomotive', 0.7383973002433777),\n",
       " ('cart', 0.7375895977020264)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most similar using cosine similarity\n",
    "model.most_similar_cosmul('wagon', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loki/.local/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trumpet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select most \"unlike\" item\n",
    "model.doesnt_match(['guitar', 'trumpet', 'violin', 'flute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room\t\n",
      "[('rooms', 0.7605786323547363), ('upstairs', 0.6226500868797302), ('hallway', 0.6086891889572144), ('downstairs', 0.593078076839447), ('bathroom', 0.5513426065444946), ('kitchenette', 0.5502405166625977), ('basement', 0.5274615287780762), ('lounge', 0.5249817967414856), ('foyer', 0.5173395276069641), ('hallways', 0.5161101222038269)]\n",
      "--------------------------------------------------\n",
      "rooms\t\n",
      "[('room', 0.7605786323547363), ('Rooms', 0.634871780872345), ('bedrooms', 0.6270223259925842), ('bathrooms', 0.6007975339889526), ('suites', 0.5960015058517456), ('beds', 0.5761682987213135), ('lounges', 0.5643664598464966), ('kitchenette', 0.561974048614502), ('lounge', 0.5320551991462708), ('floors', 0.529586672782898)]\n",
      "--------------------------------------------------\n",
      "Room\t\n",
      "[('Rooms', 0.6796290278434753), ('Ballroom', 0.6294605731964111), ('Lounge', 0.5510711669921875), ('Auditorium', 0.5282275080680847), ('Building', 0.49195849895477295), ('Cafeteria', 0.49163320660591125), ('room', 0.48523545265197754), ('auditorium', 0.4844275414943695), ('Suite', 0.46857962012290955), ('Mansion', 0.46459025144577026)]\n",
      "--------------------------------------------------\n",
      "Rooms\t\n",
      "[('Room', 0.6796290874481201), ('rooms', 0.6348718404769897), ('Ballroom', 0.4912067651748657), ('room', 0.4739283621311188), ('Hotel', 0.46703100204467773), ('Bed', 0.44229036569595337), ('bedrooms', 0.4374917149543762), ('Inn', 0.4322802424430847), ('Hotels', 0.4287785291671753), ('suites', 0.4277704060077667)]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Capitalization and pluralization can lead to different most_similar results\n",
    "for w in ('room', 'rooms', 'Room', 'Rooms'):\n",
    "    print(w,'\\t\\n', model.most_similar(w),sep=\"\")\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spain', 0.7776165008544922),\n",
       " ('Portugal', 0.6343989968299866),\n",
       " ('Argentina', 0.5653746724128723),\n",
       " ('Spanish', 0.5568934679031372),\n",
       " ('Porto', 0.5294696092605591),\n",
       " ('Italy', 0.5196953415870667),\n",
       " ('Brazil', 0.5041937828063965),\n",
       " ('Chile', 0.5033072233200073),\n",
       " ('Portuguese', 0.5029925107955933),\n",
       " ('Uruguay', 0.5019488334655762)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most_similar takes collections of vectors to be added (positive) or subtracted (negative) \n",
    "# Can use to specify an analogy: Read as \"Paris is to France as Madrid is to ?\"\"\n",
    "model.most_similar(positive=['France', 'Madrid'], negative=['Paris'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09666148"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity between two words\n",
    "model.similarity('bolt','bread')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42493808"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity between two sets of words\n",
    "model.n_similarity(['Elena','bought','the','hat','today'], ['He','rode','his','red','wagon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coupe', 0.8324612379074097),\n",
       " ('sedan', 0.6679246425628662),\n",
       " ('Bugatti', 0.6121565699577332),\n",
       " ('coachwork', 0.6103246212005615),\n",
       " ('sportiest', 0.60999596118927),\n",
       " ('sedans', 0.5992715954780579),\n",
       " ('Mustang', 0.5988028645515442),\n",
       " ('runabout', 0.5713080167770386),\n",
       " ('styling', 0.5562582612037659),\n",
       " ('hotrod', 0.5548204183578491),\n",
       " ('Jaguar', 0.5505430102348328),\n",
       " ('Giulietta', 0.5487755537033081),\n",
       " ('Volkswagens', 0.5426846742630005),\n",
       " ('streamliner', 0.5373216867446899),\n",
       " ('Chevy', 0.5369911789894104)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word('roadster',topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roadster', 1.0),\n",
       " ('coupe', 0.8324612379074097),\n",
       " ('sedan', 0.6679246425628662),\n",
       " ('Bugatti', 0.6121566295623779),\n",
       " ('coachwork', 0.6103246212005615),\n",
       " ('sportiest', 0.60999596118927),\n",
       " ('sedans', 0.5992715954780579),\n",
       " ('Mustang', 0.5988028645515442),\n",
       " ('runabout', 0.5713080167770386),\n",
       " ('styling', 0.5562582612037659),\n",
       " ('hotrod', 0.5548204183578491),\n",
       " ('Jaguar', 0.5505430102348328),\n",
       " ('Giulietta', 0.5487755537033081),\n",
       " ('Volkswagens', 0.5426846742630005),\n",
       " ('streamliner', 0.5373216867446899)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(model['roadster'],topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a custom Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How-to train custom Word2Vec model (this is trained with the Brown corpus)\n",
    "custommodel = Word2Vec(brown.sents(), size=300, window=5, min_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shoulders', 0.9721115827560425),\n",
       " ('seat', 0.9661572575569153),\n",
       " ('flying', 0.9656062126159668),\n",
       " ('holding', 0.9635875225067139),\n",
       " ('wind', 0.9608058333396912),\n",
       " ('coat', 0.9592040777206421),\n",
       " ('fingers', 0.9589619636535645),\n",
       " ('rifle', 0.9575096368789673),\n",
       " ('knocked', 0.9562466740608215),\n",
       " ('journey', 0.9559452533721924),\n",
       " ('beneath', 0.9558757543563843),\n",
       " ('wheel', 0.9556571245193481),\n",
       " ('knee', 0.9554955363273621),\n",
       " ('breath', 0.9546530246734619),\n",
       " ('shop', 0.9546340703964233)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To supress deprecation error in custom models or those loaded from saved files, prefix method call with \"wv.\"\"\n",
    "# so to call the most_similar method, use\n",
    "custommodel.wv.most_similar('wagon',topn=15)  # Note that the answers are much different from those of the pre-trained word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting lemmas with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the WordNet Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n"
     ]
    }
   ],
   "source": [
    "# The lemmatizer should be given a POS tag to return the lemma (defaults to nouns otherwise, and only works for simple cases like plurals)\n",
    "# adjective = 'a'; adverb = 'r'\n",
    "print(lemmatizer.lemmatize(\"sleeping\",pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting lemmas with StanfordCoreNLP (note: this will also return the part of speech tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an instance of StanfordCoreNLP by connecting to the server\n",
    "#nlp = StanfordCoreNLP('http://jupyterlab-nfs-corenlp', port=9000)\n",
    "nlp = StanfordCoreNLP('http://localhost', port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The day was sunny and warm.  I decided I'd go boating.\"  # text to be annotated\n",
    "props = {'annotators': 'lemma','outputFormat':'json'} # set annotator to provide lemma and get return as json (otherwise it's a string)\n",
    "res = nlp.annotate(txt, properties=props)   # apply the annotator: results are in json format\n",
    "d = json.loads(res)                         # load the json object into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d is the dictionary returned from loading the json response\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d['sentences'] is a list of dictionaries, one per sentence - so the second sentence (at index 1) is\n",
    "first_sent_d = d['sentences'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each dictionary has a key 'index' (value is integer sentence index) and a key 'tokens' (value is list of token dictionaries)\n",
    "first_sent_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each token dictionary contains (among other things) the original text, its corresponding lemma, and the POS tag:\n",
    "for tok_d in first_sent_d['tokens']:\n",
    "    print(tok_d['originalText'], tok_d['lemma'], tok_d['pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import WordNet\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('dog')  # Returns the synsets for the word \"dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('dog', pos='n')  # Restrict returned synsets to verbs (also works with NOUN, ADJ, ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific synset\n",
    "dog = wn.synset('dog.n.01')\n",
    "dog.name() # dentifies the name of the synset of this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.lemmas() # Outputs full lemmas, including part of speech and sense #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.lemma_names() # Outputs lemma names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.definition() # The gloss (or definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.examples() # examples of use(s) in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syns_ants(word):\n",
    "    synonyms = [] \n",
    "    antonyms = []      \n",
    "    for syn in wn.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "            if l.antonyms(): \n",
    "                antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "    synonyms = set(synonyms)\n",
    "    antonyms = set(antonyms)\n",
    "    return synonyms, antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns, ants = syns_ants(\"calm\")\n",
    "\n",
    "print(\"Synonyms:\",syns,\"\\n\\nAntonyms:\",ants,sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypernyms and Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.hypernyms() # Hypernyms for dog (e.g., a dog is-a ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.hyponyms() # Hyponyms for dog (e.g., each of these is-a dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.hypernym_paths() # Paths to all hypernyms (as returned by hypernyms method above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypernym Tree\n",
    "from pprint import pprint  # import pretty print \n",
    "hyp = lambda s:s.hypernyms() \n",
    "pprint(dog.tree(hyp)) # output hypernym tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = wn.synset('cat.n.01') # get cat synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.common_hypernyms(cat) # what hypernyms are common to both dogs and cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowest Common Hypernym between two synsets\n",
    "wn.synset('hairdresser.n.01').lowest_common_hypernyms(wn.synset('chef.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Hypernyms/Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=wn.synset('city.n.01') \n",
    "city.instance_hyponyms()[:10] # Lists the first 10 hyponyms of city (individual cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aca = wn.synset('acapulco.n.01')  # pick a city\n",
    "aca.instance_hypernyms() # Lists all its hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car=wn.synset('car.n.01') # get synset for car\n",
    "car.part_meronyms()[:10]  # Returns top 10 entities that compose a car (accelerator, airbag, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel = wn.synset('accelerator.n.01')  # get the synset for accelerator\n",
    "accel.part_holonyms()                  # Returns holonyms for the synset: entities that the accelerator is a part-of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Member Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = wn.synset('forest.n.01')  # get synset for forest\n",
    "forest.member_meronyms()           # Returns entities that are member-of a forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=wn.synset('tree.n.01')  # get the tree synset\n",
    "tree.member_holonyms()       # Returns entities that the tree is a member-of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substance Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bread= wn.synset('bread.n.01')  # get synset for bread\n",
    "bread.substance_meronyms()      # Returns entities that are substances of bread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flour = wn.synset('flour.n.01')  # get synset for flour\n",
    "flour.substance_holonyms()       # Returns entities flour is a substances-of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path-Based Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love = wn.synset('love.n.01')\n",
    "romance = wn.synset('romance.n.01')\n",
    "hate = wn.synset('hate.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path Similarity** (returns 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity is not synonymy\n",
    "print('Love - Romance',love.path_similarity(romance))\n",
    "print('Love - Hate',love.path_similarity(hate))\n",
    "print('Romance - Hate',romance.path_similarity(hate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leacock-Chodorow Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Love - Romance',love.lch_similarity(romance))\n",
    "print('Love - Hate',love.lch_similarity(hate))\n",
    "print('Romance - Hate',romance.lch_similarity(hate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wu-Palmer Similarity** (returns 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Love - Romance',love.wup_similarity(romance))\n",
    "print('Love - Hate',love.wup_similarity(hate))\n",
    "print('Romance - Hate',romance.wup_similarity(hate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information-Content Based Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet_ic as wic  # import that allows loading of information content\n",
    "ic = wic.ic('ic-brown.dat')                # load information content from the Brown corpus int variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lin Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Love - Romance',love.lin_similarity(romance, ic))\n",
    "print('Love - Hate',love.lin_similarity(hate, ic))\n",
    "print('Romance - Hate',romance.lin_similarity(hate, ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resnik Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Love - Romance',love.res_similarity(romance, ic))\n",
    "print('Love - Hate',love.res_similarity(hate, ic))\n",
    "print('Romance - Hate',romance.res_similarity(hate, ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jiang-Conrath Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Love - Romance',love.jcn_similarity(romance, ic))\n",
    "print('Love - Hate',love.jcn_similarity(hate, ic))\n",
    "print('Romance - Hate',romance.jcn_similarity(hate, ic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
