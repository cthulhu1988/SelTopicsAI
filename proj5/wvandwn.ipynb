{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the pruned word2vec sample in NLTK\n",
    "from nltk.data import find\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time()\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False) # load in word2vec format\n",
    "#print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's vocabulary\n",
    "vocab = set(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43981"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: words may have to be converted between lower and title case (and possibly upper case?) to see if they exist in the vocabulary\n",
    "len(model['avocado']) # dimensions of vector representing word 'avocado' (and all other words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wagons', 0.6923391819000244),\n",
       " ('buckboard', 0.5725744366645813),\n",
       " ('tractor', 0.5646649599075317),\n",
       " ('truck', 0.5361799597740173),\n",
       " ('boxcar', 0.5161231756210327),\n",
       " ('Wagon', 0.5161173939704895),\n",
       " ('stagecoach', 0.5105308890342712),\n",
       " ('van', 0.5091939568519592),\n",
       " ('boxcars', 0.508715808391571),\n",
       " ('mule', 0.49818965792655945)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('wagon', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wagons', 0.8461687564849854),\n",
       " ('buckboard', 0.7862864136695862),\n",
       " ('tractor', 0.7823317050933838),\n",
       " ('truck', 0.7680892944335938),\n",
       " ('boxcar', 0.758060872554779),\n",
       " ('Wagon', 0.7580579519271851),\n",
       " ('stagecoach', 0.7552647590637207),\n",
       " ('van', 0.7545962333679199),\n",
       " ('boxcars', 0.7543572187423706),\n",
       " ('mule', 0.7490941286087036),\n",
       " ('oxcart', 0.7466381192207336),\n",
       " ('chariot', 0.7398384809494019),\n",
       " ('buggy', 0.7397239208221436),\n",
       " ('locomotive', 0.7383973002433777),\n",
       " ('cart', 0.7375895977020264)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most similar using cosine similarity\n",
    "model.most_similar_cosmul('wagon', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trumpet'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select most \"unlike\" item\n",
    "model.doesnt_match(['guitar', 'trumpet', 'violin', 'flute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room\t\n",
      "[('rooms', 0.7605786323547363), ('upstairs', 0.6226500868797302), ('hallway', 0.6086891889572144), ('downstairs', 0.593078076839447), ('bathroom', 0.5513426065444946), ('kitchenette', 0.5502405166625977), ('basement', 0.5274615287780762), ('lounge', 0.5249817967414856), ('foyer', 0.5173395276069641), ('hallways', 0.5161101222038269)]\n",
      "--------------------------------------------------\n",
      "rooms\t\n",
      "[('room', 0.7605786323547363), ('Rooms', 0.634871780872345), ('bedrooms', 0.6270223259925842), ('bathrooms', 0.6007975339889526), ('suites', 0.5960015058517456), ('beds', 0.5761682987213135), ('lounges', 0.5643664598464966), ('kitchenette', 0.561974048614502), ('lounge', 0.5320551991462708), ('floors', 0.529586672782898)]\n",
      "--------------------------------------------------\n",
      "Room\t\n",
      "[('Rooms', 0.6796290278434753), ('Ballroom', 0.6294605731964111), ('Lounge', 0.5510711669921875), ('Auditorium', 0.5282275080680847), ('Building', 0.49195849895477295), ('Cafeteria', 0.49163320660591125), ('room', 0.48523545265197754), ('auditorium', 0.4844275414943695), ('Suite', 0.46857962012290955), ('Mansion', 0.46459025144577026)]\n",
      "--------------------------------------------------\n",
      "Rooms\t\n",
      "[('Room', 0.6796290874481201), ('rooms', 0.6348718404769897), ('Ballroom', 0.4912067651748657), ('room', 0.4739283621311188), ('Hotel', 0.46703100204467773), ('Bed', 0.44229036569595337), ('bedrooms', 0.4374917149543762), ('Inn', 0.4322802424430847), ('Hotels', 0.4287785291671753), ('suites', 0.4277704060077667)]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Capitalization and pluralization can lead to different most_similar results\n",
    "for w in ('room', 'rooms', 'Room', 'Rooms'):\n",
    "    print(w,'\\t\\n', model.most_similar(w),sep=\"\")\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spain', 0.7776165008544922),\n",
       " ('Portugal', 0.6343989968299866),\n",
       " ('Argentina', 0.5653746724128723),\n",
       " ('Spanish', 0.5568934679031372),\n",
       " ('Porto', 0.5294696092605591),\n",
       " ('Italy', 0.5196953415870667),\n",
       " ('Brazil', 0.5041937828063965),\n",
       " ('Chile', 0.5033072233200073),\n",
       " ('Portuguese', 0.5029925107955933),\n",
       " ('Uruguay', 0.5019488334655762)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most_similar takes collections of vectors to be added (positive) or subtracted (negative) \n",
    "# Can use to specify an analogy: Read as \"Paris is to France as Madrid is to ?\"\"\n",
    "model.most_similar(positive=['France', 'Madrid'], negative=['Paris'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09666148"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity between two words\n",
    "model.similarity('bolt','bread')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42493808"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity between two sets of words\n",
    "model.n_similarity(['Elena','bought','the','hat','today'], ['He','rode','his','red','wagon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coupe', 0.8324612379074097),\n",
       " ('sedan', 0.6679246425628662),\n",
       " ('Bugatti', 0.6121565699577332),\n",
       " ('coachwork', 0.6103246212005615),\n",
       " ('sportiest', 0.60999596118927),\n",
       " ('sedans', 0.5992715954780579),\n",
       " ('Mustang', 0.5988028645515442),\n",
       " ('runabout', 0.5713080167770386),\n",
       " ('styling', 0.5562582612037659),\n",
       " ('hotrod', 0.5548204183578491),\n",
       " ('Jaguar', 0.5505430102348328),\n",
       " ('Giulietta', 0.5487755537033081),\n",
       " ('Volkswagens', 0.5426846742630005),\n",
       " ('streamliner', 0.5373216867446899),\n",
       " ('Chevy', 0.5369911789894104)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word('roadster',topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roadster', 1.0),\n",
       " ('coupe', 0.8324612379074097),\n",
       " ('sedan', 0.6679246425628662),\n",
       " ('Bugatti', 0.6121566295623779),\n",
       " ('coachwork', 0.6103246212005615),\n",
       " ('sportiest', 0.60999596118927),\n",
       " ('sedans', 0.5992715954780579),\n",
       " ('Mustang', 0.5988028645515442),\n",
       " ('runabout', 0.5713080167770386),\n",
       " ('styling', 0.5562582612037659),\n",
       " ('hotrod', 0.5548204183578491),\n",
       " ('Jaguar', 0.5505430102348328),\n",
       " ('Giulietta', 0.5487755537033081),\n",
       " ('Volkswagens', 0.5426846742630005),\n",
       " ('streamliner', 0.5373216867446899)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(model['roadster'],topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a custom Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How-to train custom Word2Vec model (this is trained with the Brown corpus)\n",
    "custommodel = Word2Vec(brown.sents(), size=300, window=5, min_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shoulders', 0.9726659059524536),\n",
       " ('seat', 0.9652628302574158),\n",
       " ('flying', 0.9648684859275818),\n",
       " ('holding', 0.9638241529464722),\n",
       " ('fingers', 0.9613649845123291),\n",
       " ('wind', 0.9608621597290039),\n",
       " ('coat', 0.9593055248260498),\n",
       " ('knee', 0.9570326805114746),\n",
       " ('rifle', 0.956610918045044),\n",
       " ('knocked', 0.9565622806549072),\n",
       " ('beneath', 0.9564557075500488),\n",
       " ('shop', 0.9559034705162048),\n",
       " ('swung', 0.9555985927581787),\n",
       " ('journey', 0.9555788040161133),\n",
       " ('breath', 0.9554819464683533)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To supress deprecation error in custom models or those loaded from saved files, prefix method call with \"wv.\"\"\n",
    "# so to call the most_similar method, use\n",
    "custommodel.wv.most_similar('wagon',topn=15)  # Note that the answers are much different from those of the pre-trained word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting lemmas with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the WordNet Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n"
     ]
    }
   ],
   "source": [
    "# The lemmatizer should be given a POS tag to return the lemma (defaults to nouns otherwise, and only works for simple cases like plurals)\n",
    "# adjective = 'a'; adverb = 'r'\n",
    "print(lemmatizer.lemmatize(\"sleeping\",pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting lemmas with StanfordCoreNLP (note: this will also return the part of speech tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an instance of StanfordCoreNLP by connecting to the server\n",
    "#nlp = StanfordCoreNLP('http://jupyterlab-nfs-corenlp', port=9000)\n",
    "nlp = StanfordCoreNLP('http://localhost', port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The day was sunny and warm.  I decided I'd go boating.\"  # text to be annotated\n",
    "props = {'annotators': 'lemma','outputFormat':'json'} # set annotator to provide lemma and get return as json (otherwise it's a string)\n",
    "res = nlp.annotate(txt, properties=props)   # apply the annotator: results are in json format\n",
    "d = json.loads(res)                         # load the json object into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d is the dictionary returned from loading the json response\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d['sentences'] is a list of dictionaries, one per sentence - so the second sentence (at index 1) is\n",
    "first_sent_d = d['sentences'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each dictionary has a key 'index' (value is integer sentence index) and a key 'tokens' (value is list of token dictionaries)\n",
    "first_sent_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each token dictionary contains (among other things) the original text, its corresponding lemma, and the POS tag:\n",
    "for tok_d in first_sent_d['tokens']:\n",
    "    print(tok_d['originalText'], tok_d['lemma'], tok_d['pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import WordNet\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog')  # Returns the synsets for the word \"dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog', pos='n')  # Restrict returned synsets to verbs (also works with NOUN, ADJ, ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog.n.01'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a specific synset\n",
    "dog = wn.synset('dog.n.01')\n",
    "dog.name() # dentifies the name of the synset of this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lemmas() # Outputs full lemmas, including part of speech and sense #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lemma_names() # Outputs lemma names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.definition() # The gloss (or definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog barked all night']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.examples() # examples of use(s) in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syns_ants(word):\n",
    "    synonyms = [] \n",
    "    antonyms = []      \n",
    "    for syn in wn.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "            if l.antonyms(): \n",
    "                antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "    synonyms = set(synonyms)\n",
    "    antonyms = set(antonyms)\n",
    "    return synonyms, antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms:{'still', 'tranquilize', 'calm', 'calm_down', 'becalm', 'equanimity', 'simmer_down', 'lull', 'tranquil', 'tranquillise', 'settle_down', 'sedate', 'chill_out', 'cool_it', 'serene', 'tranquillize', 'cool_off', 'steady', 'quieten', 'unagitated', 'composure', 'calm_air', 'quiet', 'calmness'}\n",
      "\n",
      "Antonyms:{'stormy', 'discomposure', 'stimulate', 'agitate'}\n"
     ]
    }
   ],
   "source": [
    "syns, ants = syns_ants(\"calm\")\n",
    "\n",
    "print(\"Synonyms:\",syns,\"\\n\\nAntonyms:\",ants,sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypernyms and Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernyms() # Hypernyms for dog (e.g., a dog is-a ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hyponyms() # Hyponyms for dog (e.g., each of these is-a dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('entity.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('living_thing.n.01'),\n",
       "  Synset('organism.n.01'),\n",
       "  Synset('animal.n.01'),\n",
       "  Synset('chordate.n.01'),\n",
       "  Synset('vertebrate.n.01'),\n",
       "  Synset('mammal.n.01'),\n",
       "  Synset('placental.n.01'),\n",
       "  Synset('carnivore.n.01'),\n",
       "  Synset('canine.n.02'),\n",
       "  Synset('dog.n.01')],\n",
       " [Synset('entity.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('living_thing.n.01'),\n",
       "  Synset('organism.n.01'),\n",
       "  Synset('animal.n.01'),\n",
       "  Synset('domestic_animal.n.01'),\n",
       "  Synset('dog.n.01')]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernym_paths() # Paths to all hypernyms (as returned by hypernyms method above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dog.n.01'),\n",
      " [Synset('canine.n.02'),\n",
      "  [Synset('carnivore.n.01'),\n",
      "   [Synset('placental.n.01'),\n",
      "    [Synset('mammal.n.01'),\n",
      "     [Synset('vertebrate.n.01'),\n",
      "      [Synset('chordate.n.01'),\n",
      "       [Synset('animal.n.01'),\n",
      "        [Synset('organism.n.01'),\n",
      "         [Synset('living_thing.n.01'),\n",
      "          [Synset('whole.n.02'),\n",
      "           [Synset('object.n.01'),\n",
      "            [Synset('physical_entity.n.01'),\n",
      "             [Synset('entity.n.01')]]]]]]]]]]]]],\n",
      " [Synset('domestic_animal.n.01'),\n",
      "  [Synset('animal.n.01'),\n",
      "   [Synset('organism.n.01'),\n",
      "    [Synset('living_thing.n.01'),\n",
      "     [Synset('whole.n.02'),\n",
      "      [Synset('object.n.01'),\n",
      "       [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Hypernym Tree\n",
    "from pprint import pprint  # import pretty print \n",
    "hyp = lambda s:s.hypernyms() \n",
    "pprint(dog.tree(hyp)) # output hypernym tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = wn.synset('cat.n.01') # get cat synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('cat.n.01')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chordate.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('mammal.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('carnivore.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('entity.n.01'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('object.n.01')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.common_hypernyms(cat) # what hypernyms are common to both dogs and cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('skilled_worker.n.01')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowest Common Hypernym between two synsets\n",
    "wn.synset('hairdresser.n.01').lowest_common_hypernyms(wn.synset('chef.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Hypernyms/Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('aachen.n.01'),\n",
       " Synset('aalborg.n.01'),\n",
       " Synset('abadan.n.01'),\n",
       " Synset('aberdeen.n.04'),\n",
       " Synset('abidjan.n.01'),\n",
       " Synset('abilene.n.01'),\n",
       " Synset('acapulco.n.01'),\n",
       " Synset('adana.n.01'),\n",
       " Synset('aden.n.01'),\n",
       " Synset('agra.n.01')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city=wn.synset('city.n.01') \n",
    "city.instance_hyponyms()[:10] # Lists the first 10 hyponyms of city (individual cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('city.n.01'), Synset('port.n.01')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aca = wn.synset('acapulco.n.01')  # pick a city\n",
    "aca.instance_hypernyms() # Lists all its hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('accelerator.n.01'),\n",
       " Synset('air_bag.n.01'),\n",
       " Synset('auto_accessory.n.01'),\n",
       " Synset('automobile_engine.n.01'),\n",
       " Synset('automobile_horn.n.01'),\n",
       " Synset('buffer.n.06'),\n",
       " Synset('bumper.n.02'),\n",
       " Synset('car_door.n.01'),\n",
       " Synset('car_mirror.n.01'),\n",
       " Synset('car_seat.n.01')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car=wn.synset('car.n.01') # get synset for car\n",
    "car.part_meronyms()[:10]  # Returns top 10 entities that compose a car (accelerator, airbag, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('airplane.n.01'), Synset('car.n.01')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel = wn.synset('accelerator.n.01')  # get the synset for accelerator\n",
    "accel.part_holonyms()                  # Returns holonyms for the synset: entities that the accelerator is a part-of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Member Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('tree.n.01'), Synset('underbrush.n.01')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = wn.synset('forest.n.01')  # get synset for forest\n",
    "forest.member_meronyms()           # Returns entities that are member-of a forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('forest.n.01')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=wn.synset('tree.n.01')  # get the tree synset\n",
    "tree.member_holonyms()       # Returns entities that the tree is a member-of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substance Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('flour.n.01')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bread= wn.synset('bread.n.01')  # get synset for bread\n",
    "bread.substance_meronyms()      # Returns entities that are substances of bread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bread.n.01'), Synset('dough.n.01'), Synset('pastry.n.02')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flour = wn.synset('flour.n.01')  # get synset for flour\n",
    "flour.substance_holonyms()       # Returns entities flour is a substances-of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path-Based Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "love = wn.synset('love.n.01')\n",
    "romance = wn.synset('romance.n.01')\n",
    "hate = wn.synset('hate.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path Similarity** (returns 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love - Romance 0.16666666666666666\n",
      "Love - Hate 0.3333333333333333\n",
      "Romance - Hate 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# similarity is not synonymy\n",
    "print('Love - Romance',love.path_similarity(romance))\n",
    "print('Love - Hate',love.path_similarity(hate))\n",
    "print('Romance - Hate',romance.path_similarity(hate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leacock-Chodorow Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love - Romance 1.845826690498331\n",
      "Love - Hate 2.538973871058276\n",
      "Romance - Hate 1.845826690498331\n"
     ]
    }
   ],
   "source": [
    "print('Love - Romance',love.lch_similarity(romance))\n",
    "print('Love - Hate',love.lch_similarity(hate))\n",
    "print('Romance - Hate',romance.lch_similarity(hate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wu-Palmer Similarity** (returns 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love - Romance 0.6153846153846154\n",
      "Love - Hate 0.8571428571428571\n",
      "Romance - Hate 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "print('Love - Romance',love.wup_similarity(romance))\n",
    "print('Love - Hate',love.wup_similarity(hate))\n",
    "print('Romance - Hate',romance.wup_similarity(hate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information-Content Based Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet_ic as wic  # import that allows loading of information content\n",
    "ic = wic.ic('ic-brown.dat')                # load information content from the Brown corpus int variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lin Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love - Romance 0.3148881810545228\n",
      "Love - Hate 0.7071675666744289\n",
      "Romance - Hate 0.31353592105655803\n"
     ]
    }
   ],
   "source": [
    "print('Love - Romance',love.lin_similarity(romance, ic))\n",
    "print('Love - Hate',love.lin_similarity(hate, ic))\n",
    "print('Romance - Hate',romance.lin_similarity(hate, ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resnik Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love - Romance 3.139908049247135\n",
      "Love - Hate 6.089739897762795\n",
      "Romance - Hate 3.139908049247135\n"
     ]
    }
   ],
   "source": [
    "print('Love - Romance',love.res_similarity(romance, ic))\n",
    "print('Love - Hate',love.res_similarity(hate, ic))\n",
    "print('Romance - Hate',romance.res_similarity(hate, ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jiang-Conrath Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love - Romance 0.07318936425583651\n",
      "Love - Hate 0.19827794926970765\n",
      "Romance - Hate 0.07273150289041953\n"
     ]
    }
   ],
   "source": [
    "print('Love - Romance',love.jcn_similarity(romance, ic))\n",
    "print('Love - Hate',love.jcn_similarity(hate, ic))\n",
    "print('Romance - Hate',romance.jcn_similarity(hate, ic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
