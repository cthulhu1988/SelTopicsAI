{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isaac G Callison\n",
    "# 6350-001\n",
    "# Project 3\n",
    "# Due 2/13/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk import classify\n",
    "from nltk.metrics import *\n",
    "import collections\n",
    "from nltk.tokenize import word_tokenize\n",
    "import heapq\n",
    "# pull in Sotu from file \n",
    "sotu_file = 'sotu.txt'\n",
    "repub_list = [] ; dem_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presdents lists\n",
    "r_list = [\"Abraham Lincoln\",\"Ulysses S. Grant\",\"Rutherford B. Hayes\",\"James Garfield\",\"Chester a. Arthur\",\"Benjamin Harrison\",\"William McKinley\",\n",
    "    \"Theodore Roosevelt\",\"William h. Taft\",\n",
    "    \"Warren Harding\",\"Calvin Coolidge\",\"Herbert Hoover\",\"Dwight d. Eisenhower\",\"Richard Nixon\",\"Gerald r. Ford\",\"Ronald Reagan\",\"George h.w. Bush\",\n",
    "    \"George W. Bush\",\"Donald Trump\"]\n",
    "repub_list = [x.lower() for x in r_list]\n",
    "d_list = [\"Andrew Jackson\",\"Martin Van Buren\",\"james polk\",\"Franklin Pierce\",\"James Buchanan\",\"Grover Cleveland\",\"Woodrow Wilson\",\n",
    "    \"Franklin D. Roosevelt\",\"Harry s. Truman\",\"John F. Kennedy\",\"Lyndon b. Johnson\",\"Jimmy Carter\",\"william j. Clinton\",\"Barack Obama\"]\n",
    "dem_list = [y.lower() for y in d_list]\n",
    "#########################################################################################################################\n",
    "## Use an intermediate test file to strip out some non-essential words\n",
    "testFile = open(\"test.txt\",\"w+\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "## Open state of the union file and write out to test file with some non-essential characters stripped out. \n",
    "with open(sotu_file) as sf:\n",
    "    lines = sf.readlines()\n",
    "    glob = [x.replace('\\'', ' ') for x in lines]\n",
    "    glob = [x.lstrip('*') for x in glob]\n",
    "    glob = [y.replace('\\n', ' ') for y in glob]\n",
    "    glob = [y.replace('\\.', ' ') for y in glob]\n",
    "    for line in glob:\n",
    "        testFile.write(line.lower())    \n",
    "testFile.close()\n",
    "## Create seperate republican and democrat files to write SOTUs out to.\n",
    "r_file = open(\"rFile.txt\", 'w+')\n",
    "d_file = open(\"dFile.txt\", 'w+')\n",
    "f_file = open(\"f_file.txt\", 'w+')\n",
    "\n",
    "r_docs = []\n",
    "d_docs = []\n",
    "all_words = []\n",
    "## Open test file, readlines, split on '@', write out name of president and associated speech\n",
    "with open(\"test.txt\") as tf:\n",
    "    new_list = []\n",
    "    lines = tf.readlines()\n",
    "    lines = str(lines)\n",
    "    lines = lines.split('@')\n",
    "    for r,item in enumerate(lines):\n",
    "        s = item.split()\n",
    "        for w in s:\n",
    "            all_words.append(w)\n",
    "        if item in repub_list:\n",
    "            r_file.write(lines[r])\n",
    "            r_file.write('\\n')\n",
    "            r_file.write(lines[r+2])\n",
    "            r_docs.append(lines[r+2])\n",
    "            r_file.write('\\n')\n",
    "        elif item in dem_list:\n",
    "            d_file.write(lines[r])\n",
    "            d_file.write('\\n')\n",
    "            d_file.write(lines[r+2])\n",
    "            d_docs.append(lines[r+2])\n",
    "            d_file.write('\\n')\n",
    "\n",
    "r_file.close()\n",
    "d_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## variable for highest occuring n words. Use in nlargest for republicans and dems. \n",
    "N_LARGE = 50\n",
    "\n",
    "## Gets highest frequency of words in the republican speeches \n",
    "r_set = set()\n",
    "r_dict = {}\n",
    "with open(\"rFile.txt\") as rf:\n",
    "    r_lines = rf.readlines()\n",
    "    for word in r_lines:\n",
    "        word = word.split()\n",
    "        for item in word:\n",
    "            if item not in stop_words:\n",
    "                item = item.lower()\n",
    "                r_dict[item] = r_dict.get(item,0)+1 \n",
    "                r_set.add(item)       \n",
    "r_freq = heapq.nlargest(N_LARGE, r_dict, key=r_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gets highest frequency of words in the Democrat speeches \n",
    "d_set = set()\n",
    "d_dict = {}\n",
    "with open(\"dFile.txt\") as df:\n",
    "    d_lines = df.readlines()\n",
    "    for word in d_lines:\n",
    "        word = word.split()\n",
    "        for item in word:\n",
    "            if item not in stop_words:\n",
    "                item = item.lower()\n",
    "                d_set.add(item)\n",
    "                d_dict[item] = d_dict.get(item,0)+1\n",
    "\n",
    "d_freq = heapq.nlargest(N_LARGE, d_dict, key=d_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a union of the words that occur most often in BOTH republican and democrat speeches.\n",
    "## The idea is that if I pull out the words that both parties use, it will reveal the true differences \n",
    "## in speech between the parties. \n",
    "\n",
    "common_words = (set(d_freq) & set(r_freq))\n",
    "\n",
    "# Here are all the words with the common words in both sets of speeches removed.\n",
    "#all_words_freq = nltk.FreqDist(w.lower() for w in all_words if w not in common_words)\n",
    "all_words_freq = nltk.FreqDist(w.lower() for w in all_words)\n",
    "\n",
    "## leng of all words\n",
    "test_set_freq = len(all_words_freq.keys())\n",
    "#######################################################\n",
    "## percentage of all words to use in the word features. \n",
    "perc = 0.25\n",
    "######################################################\n",
    "word_features = list(all_words_freq.keys())[:(int(test_set_freq*perc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tuples from both sets of words, add label. \n",
    "tup_d = []\n",
    "for item in d_docs:\n",
    "    #i = item.split()\n",
    "    i = word_tokenize(item)\n",
    "    it = (i,\"democrat\")\n",
    "    tup_d.append(it)\n",
    "\n",
    "tup_rep = []\n",
    "for item in r_docs:\n",
    "    i = word_tokenize(item)\n",
    "    it = (i,\"republican\")\n",
    "    tup_rep.append(it)\n",
    "\n",
    "## Finally, just add all the democrat tuples to the republican tuples. \n",
    "for item in tup_d:\n",
    "    tup_rep.append(item)\n",
    "random.shuffle(tup_rep)\n",
    "#print(tup_rep[0]) (list of words,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "############################## THIS IS THE MAIN FEATURES FUNCTION ###############################################\n",
    "def find_features(sotu):\n",
    "    features = {}\n",
    "    wrds = set(sotu)\n",
    "    for w in word_features:\n",
    "        features[w] = (w in wrds)\n",
    "    ## I guess I thought republicans would use shorter words, just a hunch. Also, if a word was found in high freq\n",
    "    ## among republicans or democrats it was set to true\n",
    "#     for item in wrds:\n",
    "#         features[item] = True if len(item) <= 8 else False\n",
    "#         if item in r_freq:\n",
    "#             features[item] = True\n",
    "#         elif item in d_freq:\n",
    "#             features[item] = True \n",
    "\n",
    "    return features        \n",
    "##################################################################################################################\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a list consisting of the gender feature dictionaries: last letter of and the gender of a name\n",
    "def find_accuracy():\n",
    "    # Create featuresets and shuffle\n",
    "    featuresets = [(find_features(tup_r),r) for (tup_r, r) in tup_rep ]\n",
    "    random.shuffle(featuresets)\n",
    "\n",
    "    # training/testing is set at an 80/20 split\n",
    "    train_len = int(len(featuresets) * .80)\n",
    "    test_len = (len(featuresets) - train_len)\n",
    "    train_set, test_set = featuresets[train_len:], featuresets[:test_len]\n",
    "\n",
    "    # Train the classifer\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    \n",
    "    ############ UNCOMMENT TO PRINT INFORMATIVE FEATURES ####################\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "    \n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "    \n",
    "    for i, (feats, label) in enumerate(test_set):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "\n",
    "    # run the entire test set, and print the classifier's accuracy\n",
    "    accuracy = (classify.accuracy(classifier, test_set))\n",
    "    ## HEre are all the measures. \n",
    "    print(\"Accuracy\", acc)\n",
    "    r_prec =(precision(refsets['republican'], testsets['republican']))\n",
    "    r_recall = (recall(refsets['republican'], testsets['republican']))\n",
    "    r_measure = (f_measure(refsets['republican'], testsets['republican']))\n",
    "    d_prec = (precision(refsets['democrat'], testsets['democrat']))\n",
    "    d_recall = (recall(refsets['democrat'], testsets['democrat']))\n",
    "    d_measure = (f_measure(refsets['democrat'], testsets['democrat']))\n",
    "    return(accuracy, r_prec, r_recall, r_measure, d_prec, d_recall, d_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  became = True           democr : republ =      9.5 : 1.0\n",
      "                    safe = False          republ : democr =      7.9 : 1.0\n",
      "                promised = True           democr : republ =      7.4 : 1.0\n",
      "                   minds = True           democr : republ =      6.7 : 1.0\n",
      "                   midst = True           democr : republ =      6.7 : 1.0\n",
      "                transfer = True           democr : republ =      6.7 : 1.0\n",
      "              controlled = True           democr : republ =      6.7 : 1.0\n",
      "                 burdens = True           democr : republ =      6.7 : 1.0\n",
      "                    hand = False          republ : democr =      6.7 : 1.0\n",
      "                    half = False          republ : democr =      6.0 : 1.0\n",
      "None\n",
      "Accuracy 1.0\n",
      "Most Informative Features\n",
      "                vigorous = True           republ : democr =      7.4 : 1.0\n",
      "                becoming = True           republ : democr =      6.6 : 1.0\n",
      "               incentive = True           republ : democr =      6.6 : 1.0\n",
      "                 fortune = True           republ : democr =      5.8 : 1.0\n",
      "                consular = True           republ : democr =      5.8 : 1.0\n",
      "                  merits = True           republ : democr =      5.8 : 1.0\n",
      "                     raw = True           republ : democr =      5.8 : 1.0\n",
      "                 request = True           republ : democr =      5.8 : 1.0\n",
      "               relations = False          democr : republ =      5.4 : 1.0\n",
      "                  damage = True           republ : democr =      5.1 : 1.0\n",
      "None\n",
      "Accuracy 0.4864864864864865\n",
      "Most Informative Features\n",
      "                    eyes = True           democr : republ =      8.0 : 1.0\n",
      "                reserved = True           democr : republ =      6.9 : 1.0\n",
      "          administration = False          democr : republ =      6.9 : 1.0\n",
      "                 victory = True           democr : republ =      6.9 : 1.0\n",
      "                 respect = False          democr : republ =      6.9 : 1.0\n",
      "                embraced = True           democr : republ =      6.9 : 1.0\n",
      "                    safe = False          republ : democr =      6.5 : 1.0\n",
      "                  fellow = False          republ : democr =      6.0 : 1.0\n",
      "               committee = True           republ : democr =      6.0 : 1.0\n",
      "                 fathers = True           democr : republ =      5.9 : 1.0\n",
      "None\n",
      "Accuracy 0.7027027027027027\n"
     ]
    }
   ],
   "source": [
    "## Function takes a list of lists and performs operations, averages, returns average over any number of runs. \n",
    "def return_percentages(list):\n",
    "    new_list = []\n",
    "    sum = 0\n",
    "    for item in list:\n",
    "        for num in item:\n",
    "            sum += float(num)\n",
    "        result = sum/len(item)\n",
    "        new_list.append(result)\n",
    "        sum = 0 ; result = 0\n",
    "    return new_list\n",
    "################################################################################################\n",
    "################################## Change to run some N-number of times #########################            \n",
    "TIMES_TO_RUN = 3\n",
    "################################################################################################\n",
    "#################################################################################################\n",
    "acc_list = [] ; r_prec = [] ; d_prec = [] ; r_recall = []; d_recall = [] ;d_measure = []; r_measure = []\n",
    "list_ofLists = []\n",
    "for x in range(0,TIMES_TO_RUN):\n",
    "    acc, r_p, r_r, r_m, d_p, d_r, d_m = find_accuracy()\n",
    "    acc_list.append(acc)\n",
    "    r_prec.append(r_p)\n",
    "    d_prec.append(d_p)\n",
    "    r_recall.append(r_r)\n",
    "    d_recall.append(d_r)\n",
    "    r_measure.append(r_m)\n",
    "    d_measure.append(d_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6216216216216216\n",
      "Accuracy 0.6756756756756757\n",
      "Republican Precision  0.668888888888889\n",
      "Republican Recall  0.7057416267942583\n",
      "Republican F-Measure  0.6692510692510693\n",
      "Democrat Precision  0.5984848484848485\n",
      "Democrat Recall  0.5481481481481482\n",
      "Democrat F-Measure  0.5491767629698665\n"
     ]
    }
   ],
   "source": [
    "list_ofLists.append(acc_list)\n",
    "list_ofLists.append(r_prec)\n",
    "list_ofLists.append(d_prec)\n",
    "list_ofLists.append(r_recall)\n",
    "list_ofLists.append(d_recall)\n",
    "list_ofLists.append(r_measure)\n",
    "list_ofLists.append(d_measure)\n",
    "############## Print out the various measures averaged over n-number of runs. #######################\n",
    "p_acc, p_r_prec, p_d_prec, p_r_rec, p_d_rec, p_r_meas, p_d_meas = return_percentages(list_ofLists)\n",
    "print(\"Accuracy: \", p_acc)\n",
    "print(\"Accuracy\", acc)\n",
    "print(\"Republican Precision \", p_r_prec)\n",
    "print(\"Republican Recall \", p_r_rec)\n",
    "print(\"Republican F-Measure \", p_r_meas)\n",
    "print(\"Democrat Precision \", p_d_prec)\n",
    "print(\"Democrat Recall \", p_d_rec)\n",
    "print(\"Democrat F-Measure \", p_d_meas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Explain what you did to preprocess the data, addressing what you tried that didn’t work, and state why you\n",
    "decided on the final approach you chose (include aspects in processing requirements: punctuation, text case, …)\n",
    "\n",
    "ANSWER: I tried pulling in and parsing the presidents list, but there were too many differences between the names in the list and the names in the speeches. So I hardcoded the president names. I created an intermediate test file and wrote out the names of the presidents and the speeches in to separate files. I also removed asterisks, apostrophes, and newline characters. I created dictionaries of the most frequent words in each set of speeches, then created a set of common words in both speeches to remove. The idea is that common words among both sets of speeches would not assist in differentiation.    \n",
    "\n",
    "2. Discuss the features you chose and why: How did you arrive at them? What did you try that did not work?\n",
    "\n",
    "ANSWER: I had a real hard time finding a decent feature to use. I ended up creating a list off allwords and taking a set of the most common. Then I iterated through each word in each labeled speech and assigned a boolean to each word based on whether or not it was in those most common words. It works ok, sometimes the accuracy is very high. I also used length of words. My unfamiliarity with the Jupyter IDE, nltk, nltk methods, features, featuresets, etc. limited me.\n",
    "\n",
    "3. Use the output of the show_most_informative_features method of the classifier (the data is on a per run\n",
    "basis) and generalize why the top 5 features (over all 30 trials) worked as well as they did, given the input data.\n",
    "\n",
    "ANSWER: This was the best run using word frequency and word length over 30 runs:\n",
    "\n",
    "```\n",
    "    Most Informative Features\n",
    "                 capital = False          democr : republ =     10.0 : 1.0\n",
    "             government, = False          democr : republ =      8.7 : 1.0\n",
    "                citizens = False          democr : republ =      8.7 : 1.0\n",
    "                  fought = True           democr : republ =      8.7 : 1.0\n",
    "              protection = False          democr : republ =      7.6 : 1.0\n",
    "             republicans = True           democr : republ =      7.3 : 1.0\n",
    "                   thank = 'Rep'          democr : republ =      7.3 : 1.0\n",
    "                  matter = False          democr : republ =      7.3 : 1.0\n",
    "                    talk = 'Rep'          democr : republ =      7.3 : 1.0\n",
    "                 things. = True           democr : republ =      7.3 : 1.0\n",
    "```\n",
    "    \n",
    "4. What are the possible weaknesses of your approach? Is it likely that independence was violated? Is it\n",
    "possible that there’s double counting in your approach? Identify where. \n",
    "\n",
    "\n",
    "ANSWER: Given that I only figured out how to utilize one featureset that I KNOW worked, I think I had no choice but to accept any weaknesses it may have had. I added length of the document but I don't know if that had any effect. I am not sure what double counting refers to.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
